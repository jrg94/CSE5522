{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN71HUJQCNVgPT+FtLSVggI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrg94/CSE5522/blob/lab3/lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrgdO_tAwbfS",
        "colab_type": "text"
      },
      "source": [
        "# CSE 5522 - Lab 3\n",
        "By Jeremy Grifski"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIj108SHxH0j",
        "colab_type": "text"
      },
      "source": [
        "In this lab, we'll take a look at Hidden Markov Models (HMMs) for the Eisner Ice Cream Problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_agHmKJtwf46",
        "colab_type": "text"
      },
      "source": [
        "## Part 1: Viterbi Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmpIEeUews-S",
        "colab_type": "text"
      },
      "source": [
        "Implement the Viterbi algorithm for HMMs for Eisner's Ice Cream Problem (predict whether each day is hot or cold based on the number of ice creams eaten).  Remember that the Viterbi algorithm computes the most likely sequence for an input.\n",
        "\n",
        "Your solution should be able to handle variable length sequences (in the range of 3-5).\n",
        "\n",
        "[This zip file has observation probabilities, transition probabilities, and test data for evaluation](https://osu.instructure.com/courses/76815/files/18485497/download).  Please read the probabilities and observations from a file, do not hard-code them. (This is so that we can test with different data/probabilities.)\n",
        "\n",
        "The observation and transition probabilities have rows being the variable of interest, and columns being the conditioning variables.    For example, P(2|H) is in the 3rd row (including header), 3rd column (including row label).  The columns sum to 1.\n",
        "\n",
        "The test data has one line per sequence.  When a sequence is less than five observations long, the last columns are filled with zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGHVzel9xjMu",
        "colab_type": "text"
      },
      "source": [
        "**1.0**: Let's setup the environment for data loading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWj7C3bWyGfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bupi3P1AxsXq",
        "colab_type": "text"
      },
      "source": [
        "**1.1**: Now, we'll need to load all the data from the CSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMpCMaOJxpG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "observation_dataframe = pd.read_csv(\"observationProbs.csv\")\n",
        "test_dataframe = pd.read_csv(\"testData.csv\")\n",
        "transition_dataframe = pd.read_csv(\"transitionProbs.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rr8YULOysYU",
        "colab_type": "text"
      },
      "source": [
        "**1.2**: Let's now take a peak at our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5crPSZyyyxtR",
        "colab_type": "code",
        "outputId": "93a5406f-eb4f-403c-dc3a-5a11d570d0b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "display(\n",
        "    observation_dataframe.shape,\n",
        "    observation_dataframe.head(), \n",
        "    test_dataframe.shape, \n",
        "    test_dataframe.head(),\n",
        "    transition_dataframe.shape,\n",
        "    transition_dataframe.head()\n",
        ")"
      ],
      "execution_count": 1518,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P(x|...)</th>\n",
              "      <th>C</th>\n",
              "      <th>H</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.6407</td>\n",
              "      <td>0.0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.1481</td>\n",
              "      <td>0.5341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.2122</td>\n",
              "      <td>0.4657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   P(x|...)       C       H\n",
              "0         1  0.6407  0.0002\n",
              "1         2  0.1481  0.5341\n",
              "2         3  0.2122  0.4657"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(10, 6)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SeqNumber</th>\n",
              "      <th>Obs1</th>\n",
              "      <th>Obs2</th>\n",
              "      <th>Obs3</th>\n",
              "      <th>Obs4</th>\n",
              "      <th>Obs5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SeqNumber  Obs1  Obs2  Obs3  Obs4  Obs5\n",
              "0          1     2     3     3     2     3\n",
              "1          2     2     3     2     2     0\n",
              "2          3     3     1     3     3     1\n",
              "3          4     2     1     1     0     0\n",
              "4          5     1     1     1     2     3"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3, 4)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P(x|...)</th>\n",
              "      <th>C</th>\n",
              "      <th>H</th>\n",
              "      <th>START</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>H</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>STOP</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  P(x|...)     C     H  START\n",
              "0        C  0.86  0.07    0.5\n",
              "1        H  0.07  0.86    0.5\n",
              "2     STOP  0.07  0.07    0.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6OR6vN9DATD",
        "colab_type": "text"
      },
      "source": [
        "**1.3**: Now, let's build up some strings for indexing the data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJUFSKYvDFgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COND_PROB_LABEL = \"P(x|...)\"\n",
        "HOT_LABEL = \"H\"\n",
        "COLD_LABEL = \"C\"\n",
        "START_LABEL = \"START\"\n",
        "SEQUENCE_NUM_LABEL = \"SeqNumber\"\n",
        "LENGTH_LABEL = \"length\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1MU5_P0o42",
        "colab_type": "text"
      },
      "source": [
        "**1.4**: With our data loaded, we can begin to construct our M and C matrices—assuming the first sequence for now. Here, we will assume 0 is cold and 1 is hot. This assumption matches the input data tables.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfbG4R740yPC",
        "colab_type": "code",
        "outputId": "bf994e15-9306-421e-9f3e-d36b1fc787bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "test_dataframe_copy = test_dataframe.copy()\n",
        "\n",
        "# Gets everything but seqnumber and adds column with sequence length\n",
        "cols = test_dataframe_copy.loc[:, test_dataframe_copy.columns != SEQUENCE_NUM_LABEL]  \n",
        "test_dataframe_copy[LENGTH_LABEL] = cols.astype(bool).sum(axis=1)  \n",
        "\n",
        "# Computes dimensions of m matrix\n",
        "m_height = test_dataframe_copy.loc[test_dataframe_copy[SEQUENCE_NUM_LABEL] == 1, LENGTH_LABEL].iloc[0]\n",
        "m_width = observation_dataframe.shape[1] - 1\n",
        "\n",
        "# Creates m and c matrix\n",
        "m = np.zeros(shape=(m_height, m_width))\n",
        "c = np.zeros(shape=(m_height - 1, m_width))\n",
        "\n",
        "display(m, c)"
      ],
      "execution_count": 1520,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tb8uqRe4jrD",
        "colab_type": "text"
      },
      "source": [
        "**1.5**: At this point, we can initialize the first row of the m matrix using the following formula: M<sub>1, k</sub> = π<sub>k</sub>B<sub>k,y<sub>1</sub></sub>. Here, π represents the prior probabilities and B is the emission probability.\n",
        "\n",
        "We can get π from the START column of our transition matrix. Meanwhile, we can get B from a sequence in our test data and our observation data.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXZoICSp8T1V",
        "colab_type": "code",
        "outputId": "c253fca9-f9f7-4821-e941-fdd9dd177200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# Compute prior probabilities from transition matrix\n",
        "PRIOR_PROB_HOT = transition_dataframe.loc[transition_dataframe[COND_PROB_LABEL] == HOT_LABEL, START_LABEL].iloc[0]\n",
        "PRIOR_PROB_COLD = transition_dataframe.loc[transition_dataframe[COND_PROB_LABEL] == COLD_LABEL, START_LABEL].iloc[0]\n",
        "\n",
        "# Compute observation 1 from test data \n",
        "obs1 = test_dataframe_copy.loc[test_dataframe_copy[SEQUENCE_NUM_LABEL] == 1, cols.columns[0]].iloc[0]\n",
        "\n",
        "# Compute emission probability from observation 1\n",
        "P_OBS_GIVEN_HOT = observation_dataframe.loc[observation_dataframe[COND_PROB_LABEL] == obs1, HOT_LABEL].iloc[0]\n",
        "P_OBS_GIVEN_COLD = observation_dataframe.loc[observation_dataframe[COND_PROB_LABEL] == obs1, COLD_LABEL].iloc[0]\n",
        "\n",
        "# Compute initial probabilities\n",
        "m11 = PRIOR_PROB_COLD * P_OBS_GIVEN_COLD\n",
        "m12 = PRIOR_PROB_HOT * P_OBS_GIVEN_HOT\n",
        "\n",
        "display(\n",
        "    obs1,\n",
        "    PRIOR_PROB_HOT,\n",
        "    PRIOR_PROB_COLD,\n",
        "    P_OBS_GIVEN_HOT,\n",
        "    P_OBS_GIVEN_COLD,\n",
        "    m11,\n",
        "    m12\n",
        ")"
      ],
      "execution_count": 1521,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.5341"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.1481"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.07405"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.26705"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlcS489gGFvc",
        "colab_type": "text"
      },
      "source": [
        "**1.6**: Let's find a way to turn this initialization step into a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIIHBNVjLv9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prior_probability(transition: pd.DataFrame, given_label: str):\n",
        "  \"\"\"\n",
        "  A helper function which returns the prior probability of a label\n",
        "  \"\"\"\n",
        "  return transition.loc[transition[COND_PROB_LABEL] == given_label, START_LABEL].iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSsnknavLQBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emission_probability(observation: pd.DataFrame, given_label: str, obs: str):\n",
        "  \"\"\"\n",
        "  A helper function which returns the conditional probablity of an observation\n",
        "  given a label\n",
        "  \"\"\"\n",
        "  return observation.loc[observation[COND_PROB_LABEL] == obs, given_label].iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IdTVYSCVNoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_observation(test: pd.DataFrame, cols: pd.Series, sequence: int, obs: int):\n",
        "  \"\"\"\n",
        "  A helper function which returns an observation given a sequence number and\n",
        "  an index.\n",
        "  \"\"\"\n",
        "  return test.loc[test[SEQUENCE_NUM_LABEL] == sequence, cols.columns[obs]].iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kNyMo8GKWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_matrices(test, observation, transition, sequence):\n",
        "  test_copy = test.copy()\n",
        "\n",
        "  # Gets everything but seqnumber and adds column with sequence length\n",
        "  COLS = test_copy.loc[:, test_copy.columns != SEQUENCE_NUM_LABEL]  \n",
        "  test_copy[LENGTH_LABEL] = COLS.astype(bool).sum(axis=1)  \n",
        "\n",
        "  # Computes dimensions of m matrix\n",
        "  M_HEIGHT = test_copy.loc[test_copy[SEQUENCE_NUM_LABEL] == sequence, LENGTH_LABEL].iloc[0]\n",
        "  M_WIDTH = observation.shape[1] - 1\n",
        "\n",
        "  # Creates m and c matrix\n",
        "  m = np.zeros(shape=(M_HEIGHT, M_WIDTH))\n",
        "  c = np.zeros(shape=(M_HEIGHT - 1, M_WIDTH))\n",
        "\n",
        "  # Compute prior probabilities from transition matrix\n",
        "  PRIOR_PROB_COLD = prior_probability(transition, COLD_LABEL)\n",
        "  PRIOR_PROB_HOT = prior_probability(transition, HOT_LABEL)\n",
        "\n",
        "  # Compute observation 1 from test data \n",
        "  OBS1 = test_observation(test_copy, COLS, sequence, 0)\n",
        "\n",
        "  # Compute emission probability from observation 1\n",
        "  P_OBS1_GIVEN_COLD = emission_probability(observation, COLD_LABEL, OBS1)\n",
        "  P_OBS1_GIVEN_HOT = emission_probability(observation, HOT_LABEL, OBS1)\n",
        "\n",
        "  # Compute initial probabilities\n",
        "  M11 = PRIOR_PROB_COLD * P_OBS1_GIVEN_COLD\n",
        "  M12 = PRIOR_PROB_HOT * P_OBS1_GIVEN_HOT\n",
        "\n",
        "  m[0, 0] = M11\n",
        "  m[0, 1] = M12\n",
        "\n",
        "  return m, c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkPEvwuqJeXi",
        "colab_type": "code",
        "outputId": "ed7f97bb-51a7-454d-a7ea-8ceadb508d32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "m, c = init_matrices(test_dataframe, observation_dataframe, transition_dataframe, 1)\n",
        "display(m, c)"
      ],
      "execution_count": 1526,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.07405, 0.26705],\n",
              "       [0.     , 0.     ],\n",
              "       [0.     , 0.     ],\n",
              "       [0.     , 0.     ],\n",
              "       [0.     , 0.     ]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkgc5mrGKuWA",
        "colab_type": "text"
      },
      "source": [
        "**1.7**: With an initialization function, we can begin tackling the next step: writing a step function for each row of m and c."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo4nY3IQMTSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transition_probability(transition: pd.DataFrame, label: str, given_label: str):\n",
        "  \"\"\"\n",
        "  A helper function which returns the probability of a label today given\n",
        "  a label yesterday.\n",
        "  \"\"\"\n",
        "  return transition.loc[transition[COND_PROB_LABEL] == label, given_label].iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN-ZJ4PJSuy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_state(p_max_list: list, p_obs_given_state: float):\n",
        "  \"\"\"\n",
        "  A helper function which computes the most probable state by finding the maximum\n",
        "  probability from a list of probabilities.\n",
        "  \"\"\"\n",
        "  INDEX = np.argmax(p_max_list)\n",
        "  P_STATE_TODAY = p_obs_given_state * p_max_list[INDEX]\n",
        "  return INDEX, P_STATE_TODAY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfNT540mK-MF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def step(m, c, test, observation, transition, sequence, obs_index):\n",
        "  \"\"\"\n",
        "  A helper function which updates the m and c matrices for a given observation.\n",
        "  \"\"\"\n",
        "  COLS = test.loc[:, test.columns != SEQUENCE_NUM_LABEL]  \n",
        "  OBS = test_observation(test, COLS, sequence, obs_index)\n",
        "\n",
        "  # Compute emissions probability: B\n",
        "  P_OBS_GIVEN_COLD = emission_probability(observation, COLD_LABEL, OBS)\n",
        "  P_OBS_GIVEN_HOT = emission_probability(observation, HOT_LABEL, OBS)\n",
        "\n",
        "  # Compute transition probability: A\n",
        "  P_C_TODAY_GIVEN_C_YESTERDAY = transition_probability(transition, COLD_LABEL, COLD_LABEL)\n",
        "  P_C_TODAY_GIVEN_H_YESTERDAY = transition_probability(transition, COLD_LABEL, HOT_LABEL)\n",
        "  P_H_TODAY_GIVEN_C_YESTERDAY = transition_probability(transition, HOT_LABEL, COLD_LABEL)\n",
        "  P_H_TODAY_GIVEN_H_YESTERDAY = transition_probability(transition, HOT_LABEL, HOT_LABEL)\n",
        "\n",
        "  # Compute probabilities from previous day\n",
        "  P_COLD_YESTERDAY = m[obs_index - 1, 0]\n",
        "  P_HOT_YESTERDAY = m[obs_index - 1, 1]\n",
        "\n",
        "  # Setup the list of cold today related probabilities\n",
        "  COLD_PROBS = [\n",
        "      P_C_TODAY_GIVEN_C_YESTERDAY * P_COLD_YESTERDAY,\n",
        "      P_C_TODAY_GIVEN_H_YESTERDAY * P_HOT_YESTERDAY\n",
        "  ]\n",
        "\n",
        "  HOT_PROBS = [\n",
        "      P_H_TODAY_GIVEN_C_YESTERDAY * P_COLD_YESTERDAY,\n",
        "      P_H_TODAY_GIVEN_H_YESTERDAY * P_HOT_YESTERDAY\n",
        "  ]\n",
        "\n",
        "  # Compute index and probability for c and m\n",
        "  C_COLD_VAL, M_COLD_VAL = compute_state(COLD_PROBS, P_OBS_GIVEN_COLD)\n",
        "  C_HOT_VAL, M_HOT_VAL = compute_state(HOT_PROBS, P_OBS_GIVEN_HOT)\n",
        "\n",
        "  # Populate c and m\n",
        "  c[obs_index - 1, :] = C_COLD_VAL, C_HOT_VAL\n",
        "  m[obs_index, :] = M_COLD_VAL, M_HOT_VAL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4soIOj5UyY9",
        "colab_type": "code",
        "outputId": "8e84a947-ea7b-4adc-b6be-6538057da737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "step(m, c, test_dataframe, observation_dataframe, transition_dataframe, 1, 1)\n",
        "display(m, c)"
      ],
      "execution_count": 1530,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.07405   , 0.26705   ],\n",
              "       [0.01351353, 0.10695406],\n",
              "       [0.        , 0.        ],\n",
              "       [0.        , 0.        ],\n",
              "       [0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjyxU9jqW-77",
        "colab_type": "text"
      },
      "source": [
        "**1.8**: With the step function written, we can continually generate rows for every observation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnIRT1_gXLAh",
        "colab_type": "code",
        "outputId": "c0a3008e-2ae6-4726-d182-41039e3f670f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "for i in range(1, m.shape[0]):\n",
        "  step(m, c, test_dataframe, observation_dataframe, transition_dataframe, 1, i)\n",
        "display(m, c)"
      ],
      "execution_count": 1531,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.07405   , 0.26705   ],\n",
              "       [0.01351353, 0.10695406],\n",
              "       [0.00246611, 0.04283531],\n",
              "       [0.00044407, 0.01967537],\n",
              "       [0.00029226, 0.00788003]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI_akPT7Xs5B",
        "colab_type": "text"
      },
      "source": [
        "**1.9**: Now, it's just a matter of selecting the most likely option for the last day. For sequence 1, it's hot (1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPzA9k9NX344",
        "colab_type": "code",
        "outputId": "0f0bb4d3-26d0-42b7-ce48-b56d1a5abed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x5 = np.argmax(m[-1])\n",
        "display(x5)"
      ],
      "execution_count": 1532,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re3cOnuzZRg5",
        "colab_type": "text"
      },
      "source": [
        "**1.10** With the most likely option, let's no go back and generate the sequence. In this case, we ended up with a sequence of cold, cold, hot, cold, hot for observations 2, 3, 3, 2, 3. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPkkqFg0ZZjL",
        "colab_type": "code",
        "outputId": "992b58e8-e5cb-4f83-a99e-e9f62bd413cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sequence = list()\n",
        "sequence.insert(0, x5)\n",
        "last_index = x5\n",
        "for i in range(c.shape[0] - 1, -1, -1):\n",
        "  curr_index = int(c[i][last_index])\n",
        "  sequence.insert(0, curr_index)\n",
        "  last_index = curr_index\n",
        "display(sequence)"
      ],
      "execution_count": 1533,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z9TE1nFa-L5",
        "colab_type": "text"
      },
      "source": [
        "**1.11**: One last thing! Let's turn this sequence generation code into a function for reuse. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq_x3ZIHbGVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sequence(c, x):\n",
        "  sequence = list()\n",
        "  sequence.insert(0, x)\n",
        "  last_index = x\n",
        "  for i in range(c.shape[0] - 1, -1, -1):\n",
        "    curr_index = int(c[i][last_index])\n",
        "    sequence.insert(0, curr_index)\n",
        "    last_index = curr_index\n",
        "  return sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_LZhPWebP9b",
        "colab_type": "code",
        "outputId": "42096f41-7063-483e-f1a9-be9f0154f647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_sequence(c, x5)"
      ],
      "execution_count": 1535,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1535
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KSkXlOfciqj",
        "colab_type": "text"
      },
      "source": [
        "**1.12**: Now, for fun, let's run the Viterbi algorithm for all ten sequences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k5j5Wu1cqT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def viterbi_experiment(test, observation, transition):\n",
        "  final_sequences = []\n",
        "  for i in range(1, test_dataframe.shape[0] + 1):\n",
        "    m, c = init_matrices(test_dataframe, observation_dataframe, transition_dataframe, i)\n",
        "    for j in range(1, m.shape[0]):\n",
        "      step(m, c, test_dataframe, observation_dataframe, transition_dataframe, i, j)\n",
        "    x = np.argmax(m[-1])\n",
        "    final_sequences.append(generate_sequence(c, x))\n",
        "  return final_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw4nTIyM2Hx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dump_sequences(sequences):\n",
        "  for i, s in enumerate(sequences):\n",
        "    print(f'Sequence {i + 1}: {s}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4bJ6bmv1arx",
        "colab_type": "code",
        "outputId": "a1885625-0cac-46d8-9a53-ee8f02107e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "viterbi_sequences = viterbi_experiment(test_dataframe, observation_dataframe, transition_dataframe)\n",
        "dump_sequences(viterbi_sequences)"
      ],
      "execution_count": 1538,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 1: [1, 1, 1, 1, 1]\n",
            "Sequence 2: [1, 1, 1, 1]\n",
            "Sequence 3: [0, 0, 0, 0, 0]\n",
            "Sequence 4: [0, 0, 0]\n",
            "Sequence 5: [0, 0, 0, 0, 0]\n",
            "Sequence 6: [0, 0, 0, 0]\n",
            "Sequence 7: [1, 1, 1]\n",
            "Sequence 8: [1, 1, 0, 0]\n",
            "Sequence 9: [0, 1, 1, 1, 1]\n",
            "Sequence 10: [0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJlSjJEYwmlC",
        "colab_type": "text"
      },
      "source": [
        "## Part 2: Likelihood Sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqlENA24wyPj",
        "colab_type": "text"
      },
      "source": [
        "Using the same network, implement likelihood sampling for approximate inference.  For any test sequence, sample complete sequences of the hidden states n times, where n can range from 10 to 100000 samples. The goal is to approximate the likelihood of all possible sequences.\n",
        "\n",
        "Assuming the Viterbi sequence is \"correct\", how long (how many samples) does it take the sampler to converge so that you get the highest match between samples and the Viterbi sequence?\n",
        "\n",
        "How do I sample a sequence?  In essence, pick a length (3, 4, or 5) - pick the same lengths as each test sample.  Then, sample each weather-day (Hot/Cold) according to the distribution given by the transition network.  You will need to sample Day 1 before sampling Day 2, for example.  You will then have a complete sample of sequence length 3/4/5).  The weight of that sequence sample will be the product of the observation probabilities given the sample (why?).  You can then judge by the overall weight which the most likely weather sequence would be.  Does the best string match your Viterbi answer?\n",
        "\n",
        "Note: Technically, in the original problem there is the probability of sampling STOP given either HOT or COLD.  For this section of the homework, please just remove the STOP probability and renormalize the other two probabilities so that they sum to one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of2MRXrHMk-q",
        "colab_type": "text"
      },
      "source": [
        "**2.0**: In order to begin sampling, we'll need to write a sampling function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69mTl7jNMqno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2dPbfg3XwzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_sequence(cold_probability: float, sample_sequence: list):\n",
        "  \"\"\"\n",
        "  A helper function which appends 0 to the list of cold is more likely than hot\n",
        "  \"\"\"\n",
        "  random_num = random.random()  \n",
        "  if random_num < cold_probability:\n",
        "    sample_sequence.append(0)\n",
        "  else:\n",
        "    sample_sequence.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZTnjz5mXziH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(test: pd.DataFrame, transition: pd.DataFrame, sequence: int):\n",
        "  \"\"\"\n",
        "  A helper function which generates a sample sequence by generating random\n",
        "  numbers for each day and comparing those numbers with the transition \n",
        "  probability.\n",
        "  \"\"\"\n",
        "  sample_sequence = list()\n",
        "  COLS = test.loc[:, test.columns != SEQUENCE_NUM_LABEL]  \n",
        "  for index, obs in enumerate(COLS):\n",
        "    OBS = test_observation(test, COLS, sequence, index)\n",
        "    if OBS != 0: # Sequence continues\n",
        "      if index == 0: # Use prior probabilities for first iteration\n",
        "        PRIOR_COLD = prior_probability(transition, COLD_LABEL)\n",
        "        update_sequence(PRIOR_COLD, sample_sequence)\n",
        "      else: # Otherwise, use transition probabilities\n",
        "        if sample_sequence[index - 1] == 0: # Yesterday was cold\n",
        "          P_C_TODAY_GIVEN_COLD_YESTERDAY = transition_probability(transition, COLD_LABEL, COLD_LABEL)\n",
        "          update_sequence(P_C_TODAY_GIVEN_COLD_YESTERDAY, sample_sequence)\n",
        "        else:  # Yesterday was hot\n",
        "          P_C_TODAY_GIVEN_HOT_YESTERDAY = transition_probability(transition, COLD_LABEL, HOT_LABEL)\n",
        "          update_sequence(P_C_TODAY_GIVEN_HOT_YESTERDAY, sample_sequence)\n",
        "  return sample_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR3KU_hQR_UX",
        "colab_type": "text"
      },
      "source": [
        "**2.1**: Now that we can generate samples, we'll need to be able to compute a weight for each sample. According to the directions, we should be able to do that by computing the product of the observations probabilities for each element in the sequence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyIXceVMSS-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight(test: pd.DataFrame, observations: pd.DataFrame, sample_sequence: list, sequence: int):\n",
        "  \"\"\"\n",
        "  A helper function which computes the weight of a sequence according to the\n",
        "  obervation probabilities.\n",
        "  \"\"\"\n",
        "  product = 1\n",
        "  COLS = test.loc[:, test.columns != SEQUENCE_NUM_LABEL]  \n",
        "  for index, state in enumerate(sample_sequence):\n",
        "    obs = test_observation(test, COLS, sequence, int(index))\n",
        "    label = COLD_LABEL if state == 0 else HOT_LABEL\n",
        "    probability = emission_probability(observations, label, obs)\n",
        "    product *= probability\n",
        "  return product"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_evh0oGHRBRU",
        "colab_type": "text"
      },
      "source": [
        "**2.2**: With these functions, we're able to generate a sample sequence using random numbers and the transition probabilities. As a result, we can run experiments for each of the sequences to see if we can converge on the viterbi algorithm. As a result, we should write an experiment function which will do that for a given sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuChbi3_eAu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample_mapping(test, transition, sequence, n):\n",
        "  \"\"\"\n",
        "  A helper function which counts every sample that's generated.\n",
        "  \"\"\"\n",
        "  sequence_dict = {}\n",
        "  for i in range(n):\n",
        "    s = tuple(sample(test, transition, sequence))\n",
        "    if s in sequence_dict:\n",
        "      sequence_dict[s] += 1\n",
        "    else:\n",
        "      sequence_dict[s] = 1\n",
        "  return sequence_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9shbxHo3eVpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_best_sample_and_weight(test, observation, sequence, sequence_dict):\n",
        "  \"\"\"\n",
        "  A helper method which computes the best sample and its score.\n",
        "  \"\"\"\n",
        "  best_sample = []\n",
        "  best_score = 0\n",
        "  for s, count in sequence_dict.items():\n",
        "    w = weight(test, observation, s, sequence)\n",
        "    sequence_dict[s] = sequence_dict[s] * w\n",
        "    if sequence_dict[s] > best_score:\n",
        "      best_score = sequence_dict[s]\n",
        "      best_sample = s\n",
        "  return best_sample, best_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cml5rFrJRZ8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def likelihood_experiment(test: pd.DataFrame, observation: pd.DataFrame, transition: pd.DataFrame, n: int):\n",
        "  \"\"\"\n",
        "  A helper method which performs the likelihood experiment N times for all\n",
        "  observed sequences.\n",
        "  \"\"\"\n",
        "  final_sequences = []\n",
        "  for i in range(1, test_dataframe.shape[0] + 1):  \n",
        "    sequence_dict = generate_sample_mapping(test, transition, i, n)\n",
        "    best_sample, _ = compute_best_sample_and_weight(test, observation, i, sequence_dict)\n",
        "    final_sequences.append(best_sample)\n",
        "  return final_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd4kFPIt23rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performance(viterbi_sequences, likelihood_sequences):\n",
        "  \"\"\"\n",
        "  A helper method which calculates performance of the likelihood algorithm\n",
        "  based on how well it matches the viterbi algorithm for the same data.\n",
        "  \"\"\"\n",
        "  count = 0\n",
        "  for s1, s2 in zip(viterbi_sequences, likelihood_sequences):\n",
        "    if tuple(s1) == s2:\n",
        "      count += 1\n",
        "  print(f'Performance: {count / len(viterbi_sequences) * 100}% match')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i0zRZ36Vov6",
        "colab_type": "text"
      },
      "source": [
        "**2.3**: Now, we can run a few experiments to see if we get any matches. But first, we should renormalize the transition probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc7VWoJ8e359",
        "colab_type": "code",
        "outputId": "1ae39f21-b890-425d-9720-45195d7c017d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "transition_dataframe_copy = transition_dataframe.copy()\n",
        "base_cold = transition_dataframe_copy[COLD_LABEL][:2].sum()\n",
        "base_hot = transition_dataframe_copy[HOT_LABEL][:2].sum()\n",
        "display(base_cold, base_hot)\n",
        "transition_dataframe_copy[COLD_LABEL] /= base_cold \n",
        "transition_dataframe_copy[HOT_LABEL] /= base_hot\n",
        "transition_dataframe_copy"
      ],
      "execution_count": 1547,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.9299999999999999"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.9299999999999999"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P(x|...)</th>\n",
              "      <th>C</th>\n",
              "      <th>H</th>\n",
              "      <th>START</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C</td>\n",
              "      <td>0.924731</td>\n",
              "      <td>0.075269</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>H</td>\n",
              "      <td>0.075269</td>\n",
              "      <td>0.924731</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>STOP</td>\n",
              "      <td>0.075269</td>\n",
              "      <td>0.075269</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  P(x|...)         C         H  START\n",
              "0        C  0.924731  0.075269    0.5\n",
              "1        H  0.075269  0.924731    0.5\n",
              "2     STOP  0.075269  0.075269    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1547
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FaHSVFbltuQ",
        "colab_type": "text"
      },
      "source": [
        "**2.4**: With the updated transition table, we should be able to run our experiment for each sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qydzg9HVVvFv",
        "colab_type": "code",
        "outputId": "e3268810-e763-49b2-a3fc-f290c3d1f6e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "likelihood_sequences = likelihood_experiment(test_dataframe, observation_dataframe, transition_dataframe_copy, 10)\n",
        "dump_sequences(likelihood_sequences)\n",
        "performance(viterbi_sequences, likelihood_sequences)"
      ],
      "execution_count": 1548,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 1: (1, 1, 1, 1, 1)\n",
            "Sequence 2: (1, 1, 1, 1)\n",
            "Sequence 3: (0, 0, 0, 0, 0)\n",
            "Sequence 4: (0, 0, 0)\n",
            "Sequence 5: (0, 0, 0, 0, 0)\n",
            "Sequence 6: (0, 0, 0, 0)\n",
            "Sequence 7: (1, 1, 1)\n",
            "Sequence 8: (0, 0, 0, 0)\n",
            "Sequence 9: (0, 1, 1, 1, 0)\n",
            "Sequence 10: (0, 0, 0)\n",
            "Performance: 80.0% match\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3ded5b65-039f-44aa-8d5b-a85412f43dd0",
        "id": "XAhr_ducXNv6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "likelihood_sequences = likelihood_experiment(test_dataframe, observation_dataframe, transition_dataframe_copy, 100)\n",
        "dump_sequences(likelihood_sequences)\n",
        "performance(viterbi_sequences, likelihood_sequences)"
      ],
      "execution_count": 1549,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 1: (1, 1, 1, 1, 1)\n",
            "Sequence 2: (1, 1, 1, 1)\n",
            "Sequence 3: (0, 0, 0, 0, 0)\n",
            "Sequence 4: (0, 0, 0)\n",
            "Sequence 5: (0, 0, 0, 0, 0)\n",
            "Sequence 6: (0, 0, 0, 0)\n",
            "Sequence 7: (1, 1, 1)\n",
            "Sequence 8: (1, 1, 0, 0)\n",
            "Sequence 9: (0, 1, 1, 1, 1)\n",
            "Sequence 10: (0, 0, 0)\n",
            "Performance: 100.0% match\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8b901f30-f27a-4ab2-b900-74b74820c578",
        "id": "EFVstu54XPx6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "likelihood_sequences = likelihood_experiment(test_dataframe, observation_dataframe, transition_dataframe_copy, 1000)\n",
        "dump_sequences(likelihood_sequences)\n",
        "performance(viterbi_sequences, likelihood_sequences)"
      ],
      "execution_count": 1550,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 1: (1, 1, 1, 1, 1)\n",
            "Sequence 2: (1, 1, 1, 1)\n",
            "Sequence 3: (0, 0, 0, 0, 0)\n",
            "Sequence 4: (0, 0, 0)\n",
            "Sequence 5: (0, 0, 0, 0, 0)\n",
            "Sequence 6: (0, 0, 0, 0)\n",
            "Sequence 7: (1, 1, 1)\n",
            "Sequence 8: (1, 1, 0, 0)\n",
            "Sequence 9: (0, 1, 1, 1, 1)\n",
            "Sequence 10: (0, 0, 0)\n",
            "Performance: 100.0% match\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xWqFi8l0QUq",
        "colab_type": "code",
        "outputId": "a5691bd5-bf8a-4bd3-c6b6-4b1ef66e10a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "likelihood_sequences = likelihood_experiment(test_dataframe, observation_dataframe, transition_dataframe_copy, 10000)\n",
        "dump_sequences(likelihood_sequences)\n",
        "performance(viterbi_sequences, likelihood_sequences)"
      ],
      "execution_count": 1551,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 1: (1, 1, 1, 1, 1)\n",
            "Sequence 2: (1, 1, 1, 1)\n",
            "Sequence 3: (0, 0, 0, 0, 0)\n",
            "Sequence 4: (0, 0, 0)\n",
            "Sequence 5: (0, 0, 0, 0, 0)\n",
            "Sequence 6: (0, 0, 0, 0)\n",
            "Sequence 7: (1, 1, 1)\n",
            "Sequence 8: (1, 1, 0, 0)\n",
            "Sequence 9: (0, 1, 1, 1, 1)\n",
            "Sequence 10: (0, 0, 0)\n",
            "Performance: 100.0% match\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLE5ulFK7I3Q",
        "colab_type": "text"
      },
      "source": [
        "**2.5**: Closing comments! In general, the likelihood estimation technique is very slow, and I suspect my implementation isn't doing me any favors. As a result, I am not able to simulate each sequence for 100,000 samples. Unfortunately, 10,000 takes quite a bit of time. \n",
        "\n",
        "That said, I was able to get the likelihood estimation algorithm to converge rather quickly. In fact, 10 samples was all I needed to converge at about 80%. By 1000 samples, I pretty consistently reach convergence. However, I suspect the transition probabilities are a bit generous to me in this case. After all, we are more likely to stay hot two days in a row (i.e. 86%) than switch, so the likelihood estimation picks up on that very quickly.\n",
        "\n",
        "In general, the most interesting sequences are 8 and 9 because we don't get sweeping temperatures. Naturally, these are the sequences that fail for low samples during the likelihood algorithm because they aren't being generated. As a result, the weights have no chance of playing a role. \n",
        "\n",
        "I would be interested in seeing this algorithm play out with different probabilities, but that may be an exercise for another time."
      ]
    }
  ]
}