{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNg+LrrHQqZLZINHS0J/mzj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrg94/CSE5522/blob/lab3/lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrgdO_tAwbfS",
        "colab_type": "text"
      },
      "source": [
        "# CSE 5522 - Lab 3\n",
        "By Jeremy Grifski"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIj108SHxH0j",
        "colab_type": "text"
      },
      "source": [
        "In this lab, we'll take a look at Hidden Markov Models (HMMs) for the Eisner Ice Cream Problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_agHmKJtwf46",
        "colab_type": "text"
      },
      "source": [
        "## Part 1: Viterbi Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmpIEeUews-S",
        "colab_type": "text"
      },
      "source": [
        "Implement the Viterbi algorithm for HMMs for Eisner's Ice Cream Problem (predict whether each day is hot or cold based on the number of ice creams eaten).  Remember that the Viterbi algorithm computes the most likely sequence for an input.\n",
        "\n",
        "Your solution should be able to handle variable length sequences (in the range of 3-5).\n",
        "\n",
        "[This zip file has observation probabilities, transition probabilities, and test data for evaluation](https://osu.instructure.com/courses/76815/files/18485497/download).  Please read the probabilities and observations from a file, do not hard-code them. (This is so that we can test with different data/probabilities.)\n",
        "\n",
        "The observation and transition probabilities have rows being the variable of interest, and columns being the conditioning variables.    For example, P(2|H) is in the 3rd row (including header), 3rd column (including row label).  The columns sum to 1.\n",
        "\n",
        "The test data has one line per sequence.  When a sequence is less than five observations long, the last columns are filled with zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJlSjJEYwmlC",
        "colab_type": "text"
      },
      "source": [
        "## Part 2: Likelihood Sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqlENA24wyPj",
        "colab_type": "text"
      },
      "source": [
        "Using the same network, implement likelihood sampling for approximate inference.  For any test sequence, sample complete sequences of the hidden states n times, where n can range from 10 to 100000 samples. The goal is to approximate the likelihood of all possible sequences.\n",
        "\n",
        "Assuming the Viterbi sequence is \"correct\", how long (how many samples) does it take the sampler to converge so that you get the highest match between samples and the Viterbi sequence?\n",
        "\n",
        "How do I sample a sequence?  In essence, pick a length (3, 4, or 5) - pick the same lengths as each test sample.  Then, sample each weather-day (Hot/Cold) according to the distribution given by the transition network.  You will need to sample Day 1 before sampling Day 2, for example.  You will then have a complete sample of sequence length 3/4/5).  The weight of that sequence sample will be the product of the observation probabilities given the sample (why?).  You can then judge by the overall weight which the most likely weather sequence would be.  Does the best string match your Viterbi answer?\n",
        "\n",
        "Note: Technically, in the original problem there is the probability of sampling STOP given either HOT or COLD.  For this section of the homework, please just remove the STOP probability and renormalize the other two probabilities so that they sum to one."
      ]
    }
  ]
}