{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5e1/NznaXVEdGT8yEh4QL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrg94/CSE5522/blob/lab3/lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrgdO_tAwbfS",
        "colab_type": "text"
      },
      "source": [
        "# CSE 5522 - Lab 3\n",
        "By Jeremy Grifski"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIj108SHxH0j",
        "colab_type": "text"
      },
      "source": [
        "In this lab, we'll take a look at Hidden Markov Models (HMMs) for the Eisner Ice Cream Problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_agHmKJtwf46",
        "colab_type": "text"
      },
      "source": [
        "## Part 1: Viterbi Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmpIEeUews-S",
        "colab_type": "text"
      },
      "source": [
        "Implement the Viterbi algorithm for HMMs for Eisner's Ice Cream Problem (predict whether each day is hot or cold based on the number of ice creams eaten).  Remember that the Viterbi algorithm computes the most likely sequence for an input.\n",
        "\n",
        "Your solution should be able to handle variable length sequences (in the range of 3-5).\n",
        "\n",
        "[This zip file has observation probabilities, transition probabilities, and test data for evaluation](https://osu.instructure.com/courses/76815/files/18485497/download).  Please read the probabilities and observations from a file, do not hard-code them. (This is so that we can test with different data/probabilities.)\n",
        "\n",
        "The observation and transition probabilities have rows being the variable of interest, and columns being the conditioning variables.    For example, P(2|H) is in the 3rd row (including header), 3rd column (including row label).  The columns sum to 1.\n",
        "\n",
        "The test data has one line per sequence.  When a sequence is less than five observations long, the last columns are filled with zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGHVzel9xjMu",
        "colab_type": "text"
      },
      "source": [
        "**1.0**: Let's setup the environment for data loading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWj7C3bWyGfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bupi3P1AxsXq",
        "colab_type": "text"
      },
      "source": [
        "**1.1**: Now, we'll need to load all the data from the CSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMpCMaOJxpG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "observation_dataframe = pd.read_csv(\"observationProbs.csv\")\n",
        "test_dataframe = pd.read_csv(\"testData.csv\")\n",
        "transition_dataframe = pd.read_csv(\"transitionProbs.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rr8YULOysYU",
        "colab_type": "text"
      },
      "source": [
        "**1.2**: Let's now take a peak at our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5crPSZyyyxtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "911799f5-280d-428f-edf5-6c44e0707afb"
      },
      "source": [
        "display(\n",
        "    observation_dataframe.shape,\n",
        "    observation_dataframe.head(), \n",
        "    test_dataframe.shape, \n",
        "    test_dataframe.head(),\n",
        "    transition_dataframe.shape,\n",
        "    transition_dataframe.head()\n",
        ")"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P(x|...)</th>\n",
              "      <th>C</th>\n",
              "      <th>H</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.6407</td>\n",
              "      <td>0.0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.1481</td>\n",
              "      <td>0.5341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.2122</td>\n",
              "      <td>0.4657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   P(x|...)       C       H\n",
              "0         1  0.6407  0.0002\n",
              "1         2  0.1481  0.5341\n",
              "2         3  0.2122  0.4657"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(10, 6)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SeqNumber</th>\n",
              "      <th>Obs1</th>\n",
              "      <th>Obs2</th>\n",
              "      <th>Obs3</th>\n",
              "      <th>Obs4</th>\n",
              "      <th>Obs5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SeqNumber  Obs1  Obs2  Obs3  Obs4  Obs5\n",
              "0          1     2     3     3     2     3\n",
              "1          2     2     3     2     2     0\n",
              "2          3     3     1     3     3     1\n",
              "3          4     2     1     1     0     0\n",
              "4          5     1     1     1     2     3"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(3, 4)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P(x|...)</th>\n",
              "      <th>C</th>\n",
              "      <th>H</th>\n",
              "      <th>START</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>H</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>STOP</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  P(x|...)     C     H  START\n",
              "0        C  0.86  0.07    0.5\n",
              "1        H  0.07  0.86    0.5\n",
              "2     STOP  0.07  0.07    0.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6OR6vN9DATD",
        "colab_type": "text"
      },
      "source": [
        "**1.3**: Now, let's build up some strings for indexing the data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJUFSKYvDFgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COND_PROB_LABEL = \"P(x|...)\"\n",
        "HOT_LABEL = \"H\"\n",
        "COLD_LABEL = \"C\"\n",
        "START_LABEL = \"START\"\n",
        "SEQUENCE_NUM_LABEL = \"SeqNumber\"\n",
        "LENGTH_LABEL = \"length\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1MU5_P0o42",
        "colab_type": "text"
      },
      "source": [
        "**1.4**: With our data loaded, we can begin to construct our M and C matrices—assuming the first sequence for now. Here, we will assume 0 is cold and 1 is hot. This assumption matches the input data tables.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfbG4R740yPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "1061f48c-1306-4867-89ff-9facabd0c721"
      },
      "source": [
        "test_dataframe_copy = test_dataframe.copy()\n",
        "\n",
        "# Gets everything but seqnumber and adds column with sequence length\n",
        "cols = test_dataframe_copy.loc[:, test_dataframe_copy.columns != SEQUENCE_NUM_LABEL]  \n",
        "test_dataframe_copy[LENGTH_LABEL] = cols.astype(bool).sum(axis=1)  \n",
        "\n",
        "# Computes dimensions of m matrix\n",
        "m_height = test_dataframe_copy.loc[test_dataframe_copy[SEQUENCE_NUM_LABEL] == 1, LENGTH_LABEL].iloc[0]\n",
        "m_width = observation_dataframe.shape[1] - 1\n",
        "\n",
        "# Creates m and c matrix\n",
        "m = np.zeros(shape=(m_height, m_width))\n",
        "c = np.zeros(shape=(m_height - 1, m_width))\n",
        "\n",
        "display(m, c)"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tb8uqRe4jrD",
        "colab_type": "text"
      },
      "source": [
        "**1.5**: At this point, we can initialize the first row of the m matrix using the following formula: M<sub>1, k</sub> = π<sub>k</sub>B<sub>k,y<sub>1</sub></sub>. Here, π represents the prior probabilities and B is the emission probability.\n",
        "\n",
        "We can get π from the START column of our transition matrix. Meanwhile, we can get B from a sequence in our test data and our observation data.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXZoICSp8T1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "bcd4bdf3-6c2d-4442-d903-3cf6b77effee"
      },
      "source": [
        "# Compute prior probabilities from transition matrix\n",
        "p_hot_given_start = transition_dataframe.loc[transition_dataframe[COND_PROB_LABEL] == HOT_LABEL, START_LABEL].iloc[0]\n",
        "p_cold_given_start = transition_dataframe.loc[transition_dataframe[COND_PROB_LABEL] == COLD_LABEL, START_LABEL].iloc[0]\n",
        "\n",
        "# Compute observation 1 from test data \n",
        "obs1 = test_dataframe_copy.loc[test_dataframe_copy[SEQUENCE_NUM_LABEL] == 1, cols.columns[0]].iloc[0]\n",
        "\n",
        "# Compute emission probability from observation 1\n",
        "p_obs_given_hot = observation_dataframe.loc[observation_dataframe[COND_PROB_LABEL] == obs1, HOT_LABEL].iloc[0]\n",
        "p_obs_given_cold = observation_dataframe.loc[observation_dataframe[COND_PROB_LABEL] == obs1, COLD_LABEL].iloc[0]\n",
        "\n",
        "# Compute initial probabilities\n",
        "m11 = p_cold_given_start * p_obs_given_cold\n",
        "m12 = p_hot_given_start * p_obs_given_hot\n",
        "\n",
        "display(\n",
        "    obs1,\n",
        "    p_hot_given_start,\n",
        "    p_cold_given_start,\n",
        "    p_obs_given_hot,\n",
        "    p_obs_given_cold,\n",
        "    m11,\n",
        "    m12\n",
        ")"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.5341"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.1481"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.07405"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.26705"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlcS489gGFvc",
        "colab_type": "text"
      },
      "source": [
        "**1.6**: Let's find a way to turn this initialization step into a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIIHBNVjLv9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prior_probability(transition, label):\n",
        "  return transition.loc[transition[COND_PROB_LABEL] == label, START_LABEL].iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSsnknavLQBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emission_probability(observation, label, obs):\n",
        "  return observation.loc[observation[COND_PROB_LABEL] == obs, label].iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IdTVYSCVNoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_observation(test, cols, sequence: int, obs: int):\n",
        "  return test.loc[test[SEQUENCE_NUM_LABEL] == sequence, cols.columns[obs]].iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kNyMo8GKWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_matrices(test, observation, transition, sequence):\n",
        "  test_copy = test.copy()\n",
        "\n",
        "  # Gets everything but seqnumber and adds column with sequence length\n",
        "  COLS = test_copy.loc[:, test_copy.columns != SEQUENCE_NUM_LABEL]  \n",
        "  test_copy[LENGTH_LABEL] = COLS.astype(bool).sum(axis=1)  \n",
        "\n",
        "  # Computes dimensions of m matrix\n",
        "  M_HEIGHT = test_copy.loc[test_copy[SEQUENCE_NUM_LABEL] == sequence, LENGTH_LABEL].iloc[0]\n",
        "  M_WIDTH = observation.shape[1] - 1\n",
        "\n",
        "  # Creates m and c matrix\n",
        "  m = np.zeros(shape=(M_HEIGHT, M_WIDTH))\n",
        "  c = np.zeros(shape=(M_HEIGHT - 1, M_WIDTH))\n",
        "\n",
        "  # Compute prior probabilities from transition matrix\n",
        "  P_COLD_GIVEN_START = prior_probability(transition, COLD_LABEL)\n",
        "  P_HOT_GIVEN_START = prior_probability(transition, HOT_LABEL)\n",
        "\n",
        "  # Compute observation 1 from test data \n",
        "  OBS1 = test_observation(test_copy, COLS, sequence, 0)\n",
        "\n",
        "  # Compute emission probability from observation 1\n",
        "  P_OBS1_GIVEN_COLD = emission_probability(observation, COLD_LABEL, OBS1)\n",
        "  P_OBS1_GIVEN_HOT = emission_probability(observation, HOT_LABEL, OBS1)\n",
        "\n",
        "  # Compute initial probabilities\n",
        "  M11 = P_COLD_GIVEN_START * P_OBS1_GIVEN_COLD\n",
        "  M12 = P_HOT_GIVEN_START * P_OBS1_GIVEN_HOT\n",
        "\n",
        "  m[0, 0] = M11\n",
        "  m[0, 1] = M12\n",
        "\n",
        "  return m, c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkPEvwuqJeXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "bfa51141-f558-4502-be61-53409cb300cd"
      },
      "source": [
        "m, c = init_matrices(test_dataframe, observation_dataframe, transition_dataframe, 1)\n",
        "display(m, c)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.07405, 0.26705],\n",
              "       [0.     , 0.     ],\n",
              "       [0.     , 0.     ],\n",
              "       [0.     , 0.     ],\n",
              "       [0.     , 0.     ]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkgc5mrGKuWA",
        "colab_type": "text"
      },
      "source": [
        "**1.7**: With an initialization function, we can begin tackling the next step: writing a step function for each row of m and c."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo4nY3IQMTSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transition_probability(transition, label, given_label):\n",
        "  return transition.loc[transition[COND_PROB_LABEL] == label, given_label].iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN-ZJ4PJSuy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_state(p_max_list, p_obs_given_state):\n",
        "  INDEX = np.argmax(p_max_list)\n",
        "  P_STATE_TODAY = p_obs_given_state * p_max_list[INDEX]\n",
        "  return INDEX, P_STATE_TODAY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfNT540mK-MF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def step(m, c, test, observation, transition, sequence, obs_index):\n",
        "  COLS = test.loc[:, test.columns != SEQUENCE_NUM_LABEL]  \n",
        "  OBS = test_observation(test, COLS, sequence, obs_index)\n",
        "\n",
        "  # Compute emissions probability: B\n",
        "  P_OBS_GIVEN_COLD = emission_probability(observation, COLD_LABEL, OBS)\n",
        "  P_OBS_GIVEN_HOT = emission_probability(observation, HOT_LABEL, OBS)\n",
        "\n",
        "  # Compute transition probability: A\n",
        "  P_C_TODAY_GIVEN_C_YESTERDAY = transition_probability(transition, COLD_LABEL, COLD_LABEL)\n",
        "  P_C_TODAY_GIVEN_H_YESTERDAY = transition_probability(transition, COLD_LABEL, HOT_LABEL)\n",
        "  P_H_TODAY_GIVEN_C_YESTERDAY = transition_probability(transition, HOT_LABEL, COLD_LABEL)\n",
        "  P_H_TODAY_GIVEN_H_YESTERDAY = transition_probability(transition, HOT_LABEL, HOT_LABEL)\n",
        "\n",
        "  # Compute probabilities from previous day\n",
        "  P_COLD_YESTERDAY = m[obs_index - 1, 0]\n",
        "  P_HOT_YESTERDAY = m[obs_index - 1, 1]\n",
        "\n",
        "  # Setup the list of cold today related probabilities\n",
        "  COLD_PROBS = [\n",
        "      P_C_TODAY_GIVEN_C_YESTERDAY * P_COLD_YESTERDAY,\n",
        "      P_C_TODAY_GIVEN_H_YESTERDAY * P_HOT_YESTERDAY\n",
        "  ]\n",
        "\n",
        "  HOT_PROBS = [\n",
        "      P_H_TODAY_GIVEN_H_YESTERDAY * P_HOT_YESTERDAY,\n",
        "      P_H_TODAY_GIVEN_C_YESTERDAY * P_COLD_YESTERDAY\n",
        "  ]\n",
        "\n",
        "  # Compute index and probability for c and m\n",
        "  C_COLD_VAL, M_COLD_VAL = compute_state(COLD_PROBS, P_OBS_GIVEN_COLD)\n",
        "  C_HOT_VAL, M_HOT_VAL = compute_state(HOT_PROBS, P_OBS_GIVEN_HOT)\n",
        "\n",
        "  # Populate c and m\n",
        "  c[obs_index - 1, :] = C_COLD_VAL, C_HOT_VAL\n",
        "  m[obs_index, :] = M_COLD_VAL, M_HOT_VAL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4soIOj5UyY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "a429676f-d0f2-4714-85a8-4f9eb1c0dcb5"
      },
      "source": [
        "step(m, c, test_dataframe, observation_dataframe, transition_dataframe, 1, 1)\n",
        "display(m, c)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.07405   , 0.26705   ],\n",
              "       [0.01351353, 0.10695406],\n",
              "       [0.        , 0.        ],\n",
              "       [0.        , 0.        ],\n",
              "       [0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjyxU9jqW-77",
        "colab_type": "text"
      },
      "source": [
        "**1.8**: With the step function written, we can continually generate rows for every observation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnIRT1_gXLAh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "bf828339-bbb9-48f1-f3be-3948afcc2e8f"
      },
      "source": [
        "for i in range(1, m.shape[0]):\n",
        "  step(m, c, test_dataframe, observation_dataframe, transition_dataframe, 1, i)\n",
        "display(m, c)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.07405   , 0.26705   ],\n",
              "       [0.01351353, 0.10695406],\n",
              "       [0.00246611, 0.04283531],\n",
              "       [0.00044407, 0.01967537],\n",
              "       [0.00029226, 0.00788003]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI_akPT7Xs5B",
        "colab_type": "text"
      },
      "source": [
        "**1.9**: Now, it's just a matter of selecting the most likely option for the last day. For sequence 1, it's hot (1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPzA9k9NX344",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6efbeac2-c776-49a6-ea49-3a96500a7296"
      },
      "source": [
        "x5 = np.argmax(m[-1])\n",
        "display(x5)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re3cOnuzZRg5",
        "colab_type": "text"
      },
      "source": [
        "**1.10** With the most likely option, let's no go back and generate the sequence. In this case, we ended up with a sequence of cold, cold, hot, cold, hot for observations 2, 3, 3, 2, 3. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPkkqFg0ZZjL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d3383ae-e416-4343-9942-432b7a7075e8"
      },
      "source": [
        "sequence = list()\n",
        "sequence.insert(0, x5)\n",
        "last_index = x5\n",
        "for i in range(c.shape[0] - 1, -1, -1):\n",
        "  curr_index = int(c[i][last_index])\n",
        "  sequence.insert(0, curr_index)\n",
        "  last_index = curr_index\n",
        "display(sequence)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z9TE1nFa-L5",
        "colab_type": "text"
      },
      "source": [
        "**1.11**: One last thing! Let's turn this sequence generation code into a function for reuse. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq_x3ZIHbGVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sequence(c, x):\n",
        "  sequence = list()\n",
        "  sequence.insert(0, x)\n",
        "  last_index = x\n",
        "  for i in range(c.shape[0] - 1, -1, -1):\n",
        "    curr_index = int(c[i][last_index])\n",
        "    sequence.insert(0, curr_index)\n",
        "    last_index = curr_index\n",
        "  return sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_LZhPWebP9b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7cef2db-041f-46f2-99c9-0e1da1dc1938"
      },
      "source": [
        "generate_sequence(c, x5)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KSkXlOfciqj",
        "colab_type": "text"
      },
      "source": [
        "**1.12**: Now, for fun, let's run the Viterbi algorithm for all ten sequences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k5j5Wu1cqT6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "225673ff-ed55-4091-c3e6-55636978459f"
      },
      "source": [
        "for i in range(1, test_dataframe.shape[0] + 1):\n",
        "  m, c = init_matrices(test_dataframe, observation_dataframe, transition_dataframe, i)\n",
        "  for j in range(1, m.shape[0]):\n",
        "    step(m, c, test_dataframe, observation_dataframe, transition_dataframe, i, j)\n",
        "  x = np.argmax(m[-1])\n",
        "  print(f'Sequence {i}: {generate_sequence(c, x)}')"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 1: [0, 0, 1, 0, 1]\n",
            "Sequence 2: [0, 0, 0, 1]\n",
            "Sequence 3: [0, 0, 0, 0, 0]\n",
            "Sequence 4: [0, 0, 0]\n",
            "Sequence 5: [0, 0, 0, 0, 0]\n",
            "Sequence 6: [0, 0, 0, 0]\n",
            "Sequence 7: [0, 0, 1]\n",
            "Sequence 8: [0, 1, 0, 0]\n",
            "Sequence 9: [0, 0, 0, 0, 1]\n",
            "Sequence 10: [0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJlSjJEYwmlC",
        "colab_type": "text"
      },
      "source": [
        "## Part 2: Likelihood Sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqlENA24wyPj",
        "colab_type": "text"
      },
      "source": [
        "Using the same network, implement likelihood sampling for approximate inference.  For any test sequence, sample complete sequences of the hidden states n times, where n can range from 10 to 100000 samples. The goal is to approximate the likelihood of all possible sequences.\n",
        "\n",
        "Assuming the Viterbi sequence is \"correct\", how long (how many samples) does it take the sampler to converge so that you get the highest match between samples and the Viterbi sequence?\n",
        "\n",
        "How do I sample a sequence?  In essence, pick a length (3, 4, or 5) - pick the same lengths as each test sample.  Then, sample each weather-day (Hot/Cold) according to the distribution given by the transition network.  You will need to sample Day 1 before sampling Day 2, for example.  You will then have a complete sample of sequence length 3/4/5).  The weight of that sequence sample will be the product of the observation probabilities given the sample (why?).  You can then judge by the overall weight which the most likely weather sequence would be.  Does the best string match your Viterbi answer?\n",
        "\n",
        "Note: Technically, in the original problem there is the probability of sampling STOP given either HOT or COLD.  For this section of the homework, please just remove the STOP probability and renormalize the other two probabilities so that they sum to one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of2MRXrHMk-q",
        "colab_type": "text"
      },
      "source": [
        "**2.0**: In order to begin sampling, we'll need to write a sampling function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69mTl7jNMqno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def update_sequence(cold_probability: float, sample_sequence: list):\n",
        "  random_num = random.random()  \n",
        "  if random_num < cold_probability:\n",
        "    sample_sequence.append(0)\n",
        "  else:\n",
        "    sample_sequence.append(1)\n",
        "\n",
        "def sample(test, transition, sequence):\n",
        "  sample_sequence = list()\n",
        "  COLS = test.loc[:, test.columns != SEQUENCE_NUM_LABEL]  \n",
        "  for index, obs in enumerate(COLS):\n",
        "    OBS = test_observation(test, COLS, sequence, index)\n",
        "    if OBS != 0: # Sequence continues\n",
        "      if index == 0: # Use prior probabilities for first iteration\n",
        "        PRIOR_COLD = prior_probability(transition, COLD_LABEL)\n",
        "        update_sequence(PRIOR_COLD, sample_sequence)\n",
        "      else: # Otherwise, use transition probabilities\n",
        "        if sample_sequence[index - 1] == 0: # Yesterday was cold\n",
        "          P_C_TODAY_GIVEN_COLD_YESTERDAY = transition_probability(transition, COLD_LABEL, COLD_LABEL)\n",
        "          update_sequence(P_C_TODAY_GIVEN_COLD_YESTERDAY, sample_sequence)\n",
        "        else:  # Yesterdat was hot\n",
        "          P_C_TODAY_GIVEN_HOT_YESTERDAY = transition_probability(transition, COLD_LABEL, HOT_LABEL)\n",
        "          update_sequence(P_C_TODAY_GIVEN_HOT_YESTERDAY, sample_sequence)\n",
        "  return sample_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR3KU_hQR_UX",
        "colab_type": "text"
      },
      "source": [
        "**2.1**: Now that we can generate samples, we'll need to be able to compute a weight for each sample. According to the directions, we should be able to do that by computing the product of the observations probabilities for each element in the sequence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyIXceVMSS-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight(test, observations, sample_sequence, sequence):\n",
        "  product = 1\n",
        "  COLS = test.loc[:, test.columns != SEQUENCE_NUM_LABEL]  \n",
        "  for index, state in enumerate(sample_sequence):\n",
        "    obs = test_observation(test, COLS, sequence, int(index))\n",
        "    label = COLD_LABEL if state == 0 else HOT_LABEL\n",
        "    probability = emission_probability(observations, label, obs)\n",
        "    product *= probability\n",
        "  return product"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_evh0oGHRBRU",
        "colab_type": "text"
      },
      "source": [
        "**2.2**: With these functions, we're able to generate a sample sequence using random numbers and the transition probabilities. As a result, we can run experiments for each of the sequences to see if we can converge on the viterbi algorithm. As a result, we should write an experiment function which will do that for a given sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cml5rFrJRZ8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def experiment(test: pd.DataFrame, observation: pd.DataFrame, transition: pd.DataFrame, sequence: int, n: int):\n",
        "  best_sample = []\n",
        "  best_weight = 0\n",
        "  for i in range(n):\n",
        "    s = sample(test, transition, sequence)\n",
        "    w = weight(test, observation, s, sequence)\n",
        "    if w > best_weight:\n",
        "      best_sample = s\n",
        "      best_weight = w\n",
        "  return best_sample, best_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i0zRZ36Vov6",
        "colab_type": "text"
      },
      "source": [
        "**2.3**: Now, we can run a few experiments to see if we get any matches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qydzg9HVVvFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f073690f-a6ee-4f1e-8868-ec01fa8c60c9"
      },
      "source": [
        "s, w = experiment(test_dataframe, observation_dataframe, transition_dataframe, 1, 10)\n",
        "display(s, w)"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.028811367344428896"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4e5cd68c-9e17-4d5d-fc2b-afb497ce670e",
        "id": "XAhr_ducXNv6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "s, w = experiment(test_dataframe, observation_dataframe, transition_dataframe, 1, 100)\n",
        "display(s, w)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.028811367344428896"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "72a4b88a-a912-4a8e-c6f5-906d8a97e30e",
        "id": "EFVstu54XPx6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "s, w = experiment(test_dataframe, observation_dataframe, transition_dataframe, 1, 1000)\n",
        "display(s, w)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.028811367344428896"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}